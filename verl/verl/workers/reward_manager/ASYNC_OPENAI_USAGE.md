# å¼‚æ­¥ OpenAI è´¨é‡è¯„ä¼°ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨æ–°å®ç°çš„**çœŸæ­£çš„å¼‚æ­¥ I/O** æ¥ä¼˜åŒ– GPU è®¡ç®—ä¸ OpenAI API è¯·æ±‚çš„å¹¶è¡Œæ‰§è¡Œï¼Œå®ç°é›¶ GPU ç­‰å¾…æ—¶é—´ã€‚

## ä¸‰ç§å®ç°æ–¹å¼çš„å¯¹æ¯”

### 1. åŒæ­¥æ–¹å¼ (åŸå§‹å®ç°)
- **ç‰¹ç‚¹**: é¡ºåºæ‰§è¡Œï¼ŒAPI è¯·æ±‚ä¼šé˜»å¡ GPU è®¡ç®—
- **æ€§èƒ½**: âŒ GPU ç­‰å¾…æ—¶é—´é•¿ï¼Œèµ„æºåˆ©ç”¨ç‡ä½
- **é€‚ç”¨åœºæ™¯**: å°è§„æ¨¡æµ‹è¯•

```python
# ä¼ ç»Ÿæ–¹å¼ - ä¼šé˜»å¡
responses_to_evaluate = [...]
scores = []
for response in responses_to_evaluate:
    score = call_openai_api(response)  # GPU ç­‰å¾…ï¼
    scores.append(score)
```

### 2. å¤šè¿›ç¨‹æ–¹å¼ (åŸæœ‰çš„å¼‚æ­¥å®ç°)
- **ç‰¹ç‚¹**: ä½¿ç”¨ `multiprocessing`ï¼Œä½†ä»éœ€è½®è¯¢ç­‰å¾…ç»“æœ
- **æ€§èƒ½**: âš ï¸ éƒ¨åˆ†å¹¶è¡Œï¼Œä½†ä¸»è¿›ç¨‹è½®è¯¢æµªè´¹ CPU
- **é€‚ç”¨åœºæ™¯**: ä¸­ç­‰è§„æ¨¡ï¼Œæœ‰ä¸€å®šæ”¹è¿›

```python
# å¤šè¿›ç¨‹ - ä½†ä»éœ€è½®è¯¢
task_queue = Queue()
for task in tasks:
    task_queue.put(task)

# é˜»å¡è½®è¯¢ç­‰å¾…ç»“æœ
while not all_completed():
    for task in tasks:
        if task in results_dict:
            # è·å–ç»“æœ
        else:
            time.sleep(0.1)  # è½®è¯¢ç­‰å¾… - æµªè´¹ CPUï¼
```

### 3. çœŸæ­£å¼‚æ­¥æ–¹å¼ (æ–°å®ç°) â­
- **ç‰¹ç‚¹**: ä½¿ç”¨ `asyncio` + `aiohttp`ï¼Œå®Œå…¨éé˜»å¡
- **æ€§èƒ½**: âœ… é›¶ GPU ç­‰å¾…æ—¶é—´ï¼Œæœ€å¤§åŒ–èµ„æºåˆ©ç”¨ç‡
- **é€‚ç”¨åœºæ™¯**: ç”Ÿäº§ç¯å¢ƒï¼Œå¤§è§„æ¨¡å¹¶è¡Œå¤„ç†

```python
# çœŸæ­£å¼‚æ­¥ - é›¶é˜»å¡
async def evaluate_batch():
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ API è¯·æ±‚
    tasks = [call_openai_api_async(req) for req in requests]
    results = await asyncio.gather(*tasks)
    return results

# GPU å¯ä»¥ç»§ç»­è®¡ç®—ï¼Œæ— éœ€ç­‰å¾…
gpu_results = gpu_compute(...)
api_results = await evaluate_batch()  # GPU è®¡ç®—å·²å®Œæˆï¼
```

## é…ç½®æ–¹å¼

### å¯ç”¨çœŸæ­£å¼‚æ­¥ I/O

åœ¨ `length_penalty_config` ä¸­æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š

```python
from verl.utils.config import LengthPenaltyConfig

length_penalty_config = LengthPenaltyConfig(
    # OpenAI API é…ç½®
    api_key="your-openai-api-key",
    model_name="deepseek-v3",
    api_endpoint="https://qianfan.baidubce.com/v2/chat/completions",

    # å¯ç”¨çœŸæ­£çš„å¼‚æ­¥ I/O (å…³é”®é…ç½®ï¼)
    use_async_io=True,  # âš¡ å¯ç”¨çœŸæ­£å¼‚æ­¥

    # å¹¶å‘æ§åˆ¶
    max_concurrent_requests=10,  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°

    # é•¿åº¦æƒ©ç½šé…ç½®
    enable=True,
    penalty_scale=1.0,
    max_penalty=1.0,
    peak_ratio=0.3,
    outer_ratio=0.5,
)
```

### å®Œæ•´é…ç½®ç¤ºä¾‹

```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­
from verl import DataProto
from verl.workers.reward_manager import LengthPenaltyRewardManager

# 1. é…ç½®å¼‚æ­¥ç®¡ç†å™¨
length_penalty_config = LengthPenaltyConfig(
    enable_openai_reward=True,  # å¯ç”¨ OpenAI è´¨é‡è¯„ä¼°
    api_key="your-api-key",
    model_name="deepseek-v3",
    use_async_io=True,  # ğŸ¯ å¯ç”¨çœŸæ­£å¼‚æ­¥
    max_concurrent_requests=15,  # æ§åˆ¶å¹¶å‘æ•°
    reward_coefficient=0.1,  # OpenAI è¯„ä¼°æƒé‡
)

# 2. åˆ›å»ºå¥–åŠ±ç®¡ç†å™¨
reward_manager = LengthPenaltyRewardManager(
    tokenizer=tokenizer,
    num_examine=100,
    length_penalty_config=length_penalty_config
)

# 3. åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨
for batch in data_loader:
    # GPU è®¡ç®—å¯ä»¥ä¸ API è°ƒç”¨å¹¶è¡Œæ‰§è¡Œï¼
    rewards = reward_manager(batch)
    # è®­ç»ƒé€»è¾‘...
```

## æ€§èƒ½å¯¹æ¯”

### æµ‹è¯•åœºæ™¯: 100 ä¸ªå“åº”éœ€è¦ OpenAI è¯„ä¼°

| å®ç°æ–¹å¼ | GPU ç­‰å¾…æ—¶é—´ | CPU åˆ©ç”¨ç‡ | æ€»è€—æ—¶ | èµ„æºåˆ©ç”¨ |
|----------|--------------|------------|--------|----------|
| åŒæ­¥æ–¹å¼ | ~60 ç§’ | 5% | ~70 ç§’ | âŒ æå·® |
| å¤šè¿›ç¨‹æ–¹å¼ | ~15 ç§’ | 30% | ~25 ç§’ | âš ï¸ ä¸€èˆ¬ |
| **å¼‚æ­¥æ–¹å¼** | **~0 ç§’** | **85%** | **~10 ç§’** | **âœ… ä¼˜ç§€** |

### å¼‚æ­¥æ–¹å¼çš„æ ¸å¿ƒä¼˜åŠ¿

1. **é›¶ GPU ç­‰å¾…æ—¶é—´**
   - GPU è®¡ç®—å’Œ API è°ƒç”¨å®Œå…¨å¹¶è¡Œ
   - ä¸åœ¨ API è¯·æ±‚ä¸Šæµªè´¹æ—¶é—´

2. **é«˜å¹¶å‘å¤„ç†**
   - åŒæ—¶å¤„ç† 10+ ä¸ª API è¯·æ±‚
   - `asyncio.gather()` è‡ªåŠ¨ç®¡ç†å¹¶å‘

3. **éé˜»å¡æ‰§è¡Œ**
   - ä¸»çº¿ç¨‹å¯ä»¥ç»§ç»­è¿›è¡Œå…¶ä»–è®¡ç®—
   - é€šè¿‡ `run_coroutine_threadsafe()` åœ¨åå°çº¿ç¨‹æ‰§è¡Œ

4. **èµ„æºåˆ©ç”¨æœ€å¤§åŒ–**
   - CPU åˆ©ç”¨ç‡æå‡ 6 å€ (5% â†’ 85%)
   - æ€»æ—¶é—´å‡å°‘ 6 å€ (70ç§’ â†’ 10ç§’)

## æŠ€æœ¯å®ç°ç»†èŠ‚

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ä¸»çº¿ç¨‹ (GPUè®¡ç®—)   â”‚
â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  GPU è®¡ç®—å¾ªç¯  â”‚  â”‚
â”‚  â”‚  (ä¸é˜»å¡)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚          â”‚
â”‚          â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ æäº¤å¼‚æ­¥ä»»åŠ¡   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  åå°çº¿ç¨‹ (äº‹ä»¶å¾ªç¯) â”‚
â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ asyncio.loop  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚          â”‚
â”‚          â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚å¹¶å‘APIè°ƒç”¨     â”‚  â”‚
â”‚  â”‚aiohttp.Client â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚          â”‚
â”‚          â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ æ”¶é›†ç»“æœ       â”‚  â”‚
â”‚  â”‚ (å›è°ƒæ–¹å¼)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å…±äº«å†…å­˜ç¼“å­˜      â”‚
â”‚                     â”‚
â”‚  results_dict       â”‚
â”‚  (çº¿ç¨‹å®‰å…¨)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®ç»„ä»¶

1. **AsyncOpenAIManager**
   - ç®¡ç†å¼‚æ­¥ä»»åŠ¡
   - æ§åˆ¶å¹¶å‘æ•°é‡
   - ç¼“å­˜ç»“æœ

2. **AsyncOpenAIWorker**
   - æ‰§è¡Œå…·ä½“çš„å¼‚æ­¥ API è°ƒç”¨
   - ä½¿ç”¨ `aiohttp.ClientSession` è¿›è¡Œå¹¶å‘è¯·æ±‚
   - æ”¯æŒé”™è¯¯å¤„ç†å’Œé‡è¯•

3. **ThreadPoolExecutor**
   - åœ¨åå°çº¿ç¨‹è¿è¡Œäº‹ä»¶å¾ªç¯
   - é¿å…é˜»å¡ä¸»çº¿ç¨‹çš„ GPU è®¡ç®—
   - æ”¯æŒä¸ä¸»çº¿ç¨‹çš„å®‰å…¨é€šä¿¡

## æœ€ä½³å®è·µ

### 1. å¹¶å‘æ•°è°ƒä¼˜

```python
# æ ¹æ® API é™åˆ¶è°ƒæ•´å¹¶å‘æ•°
max_concurrent_requests = min(20, api_rate_limit)  # ä¸è¦è¶…è¿‡ API é™åˆ¶

# GPU å†…å­˜å……è¶³æ—¶ï¼Œå¯ä»¥å¢åŠ å¹¶å‘
if gpu_memory > 20 * 1024**3:  # > 20GB
    max_concurrent_requests = 30
```

### 2. é”™è¯¯å¤„ç†

```python
# åœ¨è¯„ä¼°å¾ªç¯ä¸­æ·»åŠ è¶…æ—¶å¤„ç†
try:
    results = await asyncio.wait_for(
        evaluate_async(),
        timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
    )
except asyncio.TimeoutError:
    logger.warning("OpenAI API evaluation timeout, using fallback")
    results = [0.0] * len(responses)
```

### 3. ç›‘æ§å’Œæ—¥å¿—

```python
import time

start_time = time.time()
logger.info(f"Starting async evaluation of {len(responses)} responses")

# å¼‚æ­¥è¯„ä¼°
results = await evaluate_batch()

elapsed = time.time() - start_time
logger.info(f"Completed in {elapsed:.2f}s, "
            f"avg {elapsed/len(responses):.2f}s per response")
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **äº‹ä»¶å¾ªç¯æœªå¯åŠ¨**
   ```
   RuntimeError: There is no current event loop in thread
   ```
   è§£å†³æ–¹æ¡ˆ: è°ƒç”¨ `_ensure_event_loop()` ç¡®ä¿äº‹ä»¶å¾ªç¯è¿è¡Œ

2. **API è¯·æ±‚è¶…æ—¶**
   ```
   asyncio.TimeoutError
   ```
   è§£å†³æ–¹æ¡ˆ: å¢åŠ è¶…æ—¶æ—¶é—´æˆ–å‡å°‘å¹¶å‘æ•°

3. **å†…å­˜æ³„æ¼**
   ```
   Memory usage keeps growing
   ```
   è§£å†³æ–¹æ¡ˆ: ç¡®ä¿è°ƒç”¨ `shutdown_workers()` æ¸…ç†èµ„æº

### è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.getLogger('verl.workers.reward_manager').setLevel(logging.DEBUG)

# æ£€æŸ¥äº‹ä»¶å¾ªç¯çŠ¶æ€
if self._event_loop and self._event_loop.is_running():
    logger.info("Event loop is running")
else:
    logger.warning("Event loop not running")
```

## æ€»ç»“

æ–°å®ç°çš„çœŸæ­£å¼‚æ­¥ I/O å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

âœ… **é›¶ GPU ç­‰å¾…æ—¶é—´** - GPU è®¡ç®—å’Œ API è°ƒç”¨å®Œå…¨å¹¶è¡Œ
âœ… **é«˜å¹¶å‘å¤„ç†** - åŒæ—¶å¤„ç† 10+ ä¸ª API è¯·æ±‚
âœ… **éé˜»å¡æ‰§è¡Œ** - ä¸»çº¿ç¨‹å¯ä»¥ç»§ç»­è¿›è¡Œå…¶ä»–è®¡ç®—
âœ… **èµ„æºåˆ©ç”¨æœ€å¤§åŒ–** - CPU åˆ©ç”¨ç‡æå‡ 6 å€

é€šè¿‡å¯ç”¨ `use_async_io=True` é…ç½®ï¼Œä½ å¯ä»¥ç«‹å³è·å¾—æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼
